{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from language_learning_tools.grouping.vocab_grouping import \\\n",
    "    get_hangul_hanja_tuples, \\\n",
    "    group_lang_df_by_parts\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_CSV_PATH = '../input_generated_files/english_hangul_hanja_tups_to_memorize.csv'\n",
    "OUTPUT_CSV_PATH = '../output/tups_grouped_by_hangul_hanja.csv'\n",
    "ENGLISH_COL_NAME = 'English_translation'\n",
    "KOREAN_COL_NAME = 'hangul_word'\n",
    "HANJA_COL_NAME = 'hanja_word_with_x'\n",
    "\n",
    "HANJA_HANGUL_TUPLE = 'hangul_hanja_tuple'\n",
    "HANJA_HANGUL_CHAR_TUPLE = 'hangul_hanja_char_tuple'\n",
    "\n",
    "HANJA_CHAR_COL_NAME = 'hanja_char'\n",
    "\n",
    "HANJA_PARTS_COL_NAME = 'hanja_parts'\n",
    "\n",
    "eng_kor_df = pd.read_csv(INPUT_CSV_PATH)\n",
    "\n",
    "eng_kor_df = eng_kor_df[eng_kor_df['hanja_word_with_x'].apply(lambda x: 'X' not in x)]\n",
    "eng_kor_df[HANJA_HANGUL_TUPLE] = eng_kor_df.apply(lambda row: (row[KOREAN_COL_NAME], row[HANJA_COL_NAME]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "eng_kor_df['hangul_hanja_pairs'] = eng_kor_df[HANJA_HANGUL_TUPLE].apply(get_hangul_hanja_tuples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "hangul_hanja_pairs = set()\n",
    "for _pair_list in list(eng_kor_df['hangul_hanja_pairs']):\n",
    "    hangul_hanja_pairs.update(_pair_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "hangul_hanja_pairs_lst = list(hangul_hanja_pairs)\n",
    "hangul_hanja_pairs_lst.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "hangul_hanja_df = pd.DataFrame(hangul_hanja_pairs_lst).rename(columns={\n",
    "    0: 'hangul_char',\n",
    "    1: 'hanja_char'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "hangul_hanja_df.to_csv('../output/hangul_hanja_char_pairs.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}